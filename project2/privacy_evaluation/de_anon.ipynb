{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from grid import location_to_cell_id\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook for attacks 1 and 2 of paper\n",
    "\n",
    "## 0. Read Dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      poi_id  cell_id     poi_type        lat       lon\n",
      "0        307        1          bar  46.504486  6.559631\n",
      "1        331        1          bar  46.500259  6.554721\n",
      "2        578        1  supermarket  46.506017  6.551165\n",
      "3        897        1         club  46.504494  6.553889\n",
      "4        972        1  supermarket  46.502984  6.550519\n",
      "...      ...      ...          ...        ...       ...\n",
      "1055     372      100   restaurant  46.563852  6.648454\n",
      "1056     649      100          bar  46.564047  6.640250\n",
      "1057     730      100          gym  46.565961  6.642228\n",
      "1058     828      100         club  46.569177  6.642401\n",
      "1059     990      100          bar  46.565290  6.640855\n",
      "\n",
      "[1060 rows x 5 columns]\n",
      "           ip_address        lat       lon   timestamp poi_type_query\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria\n",
      "...               ...        ...       ...         ...            ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant\n",
      "\n",
      "[20443 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "pois_df = pd.read_csv('pois.csv', sep=' ')\n",
    "queries_df = pd.read_csv('queries.csv', sep=' ')\n",
    "\n",
    "print(pois_df)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Feature Engineering and Extraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ip_address        lat       lon   timestamp poi_type_query  cell_id\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria       45\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant       45\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant       76\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria       76\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria       45\n",
      "...               ...        ...       ...         ...            ...      ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket       38\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket       38\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym       38\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket       38\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant       38\n",
      "\n",
      "[20443 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extract cell_id from which query happened\n",
    "def get_cell_id(row):\n",
    "    return location_to_cell_id(row['lat'], row['lon'])\n",
    "\n",
    "queries_df['cell_id'] = queries_df.apply(lambda row: get_cell_id(row), axis=1)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14110    0.98.248.97  46.546740  6.577377   11.516781      cafeteria       63   \n",
      "14111    0.98.248.97  46.546740  6.577377   11.516781     restaurant       63   \n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14114    0.98.248.97  46.546740  6.577377   34.866475      cafeteria       63   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4151   97.138.146.97  46.520518  6.568483  447.896803            gym       22   \n",
      "4152   97.138.146.97  46.520518  6.568483  465.134875    supermarket       22   \n",
      "4153   97.138.146.97  46.503018  6.642813  465.134875            bar       10   \n",
      "4154   97.138.146.97  46.501978  6.645289  465.134875            gym       10   \n",
      "4155   97.138.146.97  46.521116  6.640636  465.134875           dojo       40   \n",
      "\n",
      "       day  time      daytime  \n",
      "14110    1    11    2.Morning  \n",
      "14111    1    11    2.Morning  \n",
      "14112    1    18    4.Evening  \n",
      "14113    1    18    4.Evening  \n",
      "14114    2    10    2.Morning  \n",
      "...    ...   ...          ...  \n",
      "4151    19    15  3.Afternoon  \n",
      "4152    20     9    2.Morning  \n",
      "4153    20     9    2.Morning  \n",
      "4154    20     9    2.Morning  \n",
      "4155    20     9    2.Morning  \n",
      "\n",
      "[20443 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Get day of the query and time\n",
    "def get_day(row):\n",
    "    return ceil(row['timestamp'] / 24)\n",
    "\n",
    "def get_hour_of_day(row):\n",
    "    return int(row['timestamp'] % 24)\n",
    "\n",
    "queries_df['day'] = queries_df.apply(lambda row: get_day(row), axis=1)\n",
    "queries_df['time'] = queries_df.apply(lambda row: get_hour_of_day(row), axis=1)\n",
    "\n",
    "#Get daytime\n",
    "def get_daytime(row):\n",
    "    time = row['time']\n",
    "    if (time >= 0 and time < 9):\n",
    "        return '1.Early'\n",
    "    if (time >= 9 and time < 12):\n",
    "        return '2.Morning'\n",
    "    if (time >= 12 and time < 17):\n",
    "        return '3.Afternoon'\n",
    "    if (time >= 17 and time < 20):\n",
    "        return '4.Evening'\n",
    "    if (time >= 20 and time < 24):\n",
    "        return '5.Night'\n",
    "queries_df['daytime'] = queries_df.apply(lambda row: get_daytime(row), axis=1)\n",
    "queries_df = queries_df.sort_values(by=['ip_address', 'day', 'time'])\n",
    "print(queries_df)\n",
    "queries_df.to_csv('queries_extended.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ip_address      daytime  day  cell_id  count\n",
      "0       0.98.248.97    2.Morning    1       63      2\n",
      "1       0.98.248.97    4.Evening    1       18      2\n",
      "2       0.98.248.97    2.Morning    2       63      2\n",
      "3       0.98.248.97      5.Night    2       18      4\n",
      "4       0.98.248.97    2.Morning    3       63      2\n",
      "...             ...          ...  ...      ...    ...\n",
      "9672  97.138.146.97  3.Afternoon   19       22      2\n",
      "9673  97.138.146.97  3.Afternoon   19       53      2\n",
      "9674  97.138.146.97    2.Morning   20       10      2\n",
      "9675  97.138.146.97    2.Morning   20       22      1\n",
      "9676  97.138.146.97    2.Morning   20       40      1\n",
      "\n",
      "[9677 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm queries_grouped.csv\n",
    "queries_grouped = queries_df.groupby(['ip_address', 'daytime', 'day','cell_id'])\\\n",
    "    .size().sort_index(level=[0,2,1])\n",
    "#queries_grouped = queries_grouped.where(queries_grouped['count'] > 4).dropna()\n",
    "\n",
    "queries_grouped = queries_grouped.to_frame(name='count').reset_index()\n",
    "print(queries_grouped)\n",
    "queries_grouped.to_csv('queries_grouped.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "queries_grouped contains, for each ip, for each day and daytime,\n",
    "the number of queries launched from a certain cell_id.\n",
    "It could be useful for inferring movement patterns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "!rm max_cell_daytime.csv\n",
    "queries_grouped_day_removed = queries_grouped.drop(['day'],axis = 1)\n",
    "max_cell_daytime = queries_grouped_day_removed.groupby(['ip_address','daytime'])\\\n",
    "    .agg(['max'])\n",
    "max_cell_daytime.to_csv('max_cell_daytime.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "max_cell_daytime contains, for each ip, for each daytime, the cell\n",
    "from which most queries have been made.\n",
    "It could be useful to individuate home/work cell id in grid.\n",
    "The assumption here is that users are on average\n",
    "habitudinary people, such that each day, for each daytime,\n",
    "the set of cells does not vary too much."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#reset the multi index manually\n",
    "#i.e just removed first two rows from stats2 and created header\n",
    "\n",
    "!sed -i -e 1,3d max_cell_daytime.csv\n",
    "!echo -e \"ip_address,daytime,cell_id,count\\n$(cat max_cell_daytime.csv)\" > max_cell_daytime.csv\n",
    "\n",
    "max_cell_daytime = pd.read_csv('max_cell_daytime.csv', sep=',', header='infer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14116    0.98.248.97  46.510700  6.628843   44.419632     restaurant       18   \n",
      "14117    0.98.248.97  46.510700  6.628843   44.419632           dojo       18   \n",
      "14118    0.98.248.97  46.513656  6.629130   44.484873    supermarket       18   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4145   97.138.146.97  46.535919  6.575488  420.080602     restaurant       53   \n",
      "4146   97.138.146.97  46.520518  6.568483  426.834979            gym       22   \n",
      "4147   97.138.146.97  46.520518  6.568483  426.834979           dojo       22   \n",
      "4148   97.138.146.97  46.535919  6.575488  444.091082      cafeteria       53   \n",
      "4149   97.138.146.97  46.535919  6.575488  444.091082     restaurant       53   \n",
      "\n",
      "       day  time      daytime  \n",
      "14112    1    18    4.Evening  \n",
      "14113    1    18    4.Evening  \n",
      "14116    2    20      5.Night  \n",
      "14117    2    20      5.Night  \n",
      "14118    2    20      5.Night  \n",
      "...    ...   ...          ...  \n",
      "4145    18    12  3.Afternoon  \n",
      "4146    18    18    4.Evening  \n",
      "4147    18    18    4.Evening  \n",
      "4148    19    12  3.Afternoon  \n",
      "4149    19    12  3.Afternoon  \n",
      "\n",
      "[15127 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "! rm queries_filtered.csv\n",
    "class Filter:\n",
    "    def __init__(self, max_cell_daytime):\n",
    "        self.max_cell_daytime = max_cell_daytime\n",
    "\n",
    "    def filter_locations(self, user, daytime, cell_id):\n",
    "        max_cell_daytime = self.max_cell_daytime\n",
    "        cell = max_cell_daytime.loc[(max_cell_daytime['ip_address'] == user) & (max_cell_daytime['daytime'] == daytime)]['cell_id'].to_numpy()[0]\n",
    "        if cell_id != cell:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "custom_filter = Filter(max_cell_daytime)\n",
    "queries_df['filter'] = np.vectorize(custom_filter.filter_locations)(queries_df['ip_address'], queries_df['daytime'], queries_df['cell_id'])\n",
    "queries_df_filtered = queries_df[queries_df['filter'] == True].drop(columns=['filter'])\\\n",
    "    .sort_values(by=['ip_address', 'day', 'time', 'daytime'], axis=0)\n",
    "print(queries_df_filtered)\n",
    "queries_df_filtered.to_csv('queries_filtered.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "filtering queries with locations from cell_id which\n",
    "turned out to be the most interesting cells, for each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Infer users' co location using trajectory similarities\n",
    "\n",
    "### 3.1\n",
    "Here we try to study, for each user, on a daily basis, their\n",
    "trajectories and how they differ from day to day. For\n",
    "computing the similarity, Frechet distance is used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: similaritymeasures in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (0.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (from similaritymeasures) (1.20.2)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (from similaritymeasures) (1.6.3)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\r\n",
      "You should consider upgrading via the '/home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install similaritymeasures\n",
    "!rm -r ./daily_trajectories\n",
    "!mkdir ./daily_trajectories\n",
    "\n",
    "from similaritymeasures import frechet_dist\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "users = queries_df['ip_address'].drop_duplicates().tolist()\n",
    "days = [_ for _ in range(1,21)]\n",
    "user_trajectories_per_day = []\n",
    "user_trajectories_cluster = []\n",
    "\n",
    "def compute_distance_matrix(trajectories):\n",
    "    n = len(trajectories)\n",
    "    dist_m = np.zeros((n, n))\n",
    "    for i in range(n - 1):\n",
    "        p = trajectories[i]\n",
    "        for j in range(i, n):\n",
    "            q = trajectories[j]\n",
    "            dist_m[i, j] = frechet_dist(np.radians(p), np.radians(q))\n",
    "            dist_m[j, i] = dist_m[i, j]\n",
    "    return dist_m\n",
    "\n",
    "def clustering_by_dbscan(distance_matrix, eps=100):\n",
    "    \"\"\"\n",
    "    :param eps: unit m for Frechet distance. Should be converted from radians\n",
    "    \"\"\"\n",
    "    db = DBSCAN(eps=eps, min_samples=1, metric='precomputed').fit(distance_matrix)\n",
    "    return db.labels_\n",
    "\n",
    "for user in users:\n",
    "    max_points = queries_df[(queries_df['ip_address'] == user)].groupby('day').size().agg(['max'])\n",
    "    max_points = max_points.to_numpy()[0]\n",
    "    trajectories_per_day = []\n",
    "    ticks = []\n",
    "    for day in days:\n",
    "        serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['day'] == day)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        if len(x) != 0 and len(y) != 0:\n",
    "            ticks.append(str(day))\n",
    "            while len(x) < max_points:\n",
    "                #fill trajectory with last known position\n",
    "                x.append(x[-1])\n",
    "                y.append(y[-1])\n",
    "            assert len(x) == max_points\n",
    "            assert len(y) == max_points\n",
    "            trajectory = np.zeros((max_points,2))\n",
    "            trajectory[:,0] = x\n",
    "            trajectory[:,1] = y\n",
    "            trajectories_per_day.append(trajectory)\n",
    "\n",
    "    dist_m = compute_distance_matrix(trajectories_per_day)\n",
    "    sns.set(font_scale = 2)\n",
    "    fig = plt.figure(figsize=(42,21))\n",
    "    ax = sns.heatmap(dist_m, linewidths=1,\n",
    "                     linecolor='white',\n",
    "                     xticklabels=ticks,\n",
    "                     yticklabels=ticks)\n",
    "    plt.savefig(f'./daily_trajectories/{user}-matrix.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results: User trajectories\n",
    "are almost the same on a daily basis. In order to validate the results,\n",
    "we used dbscan clustering and checked if the number of clusters\n",
    "of trajectories per user was 1.\n",
    "Frechet distance is a good metric.\n",
    "\n",
    "### 3.2 - De Anonimization of trajectories attack\n",
    "Here we compare users trajectory to see\n",
    "if some users have commons patterns. In order to reduce the\n",
    "number of users compared, we considered one day at time.\n",
    "\n",
    "### Adversarial Model\n",
    "The adversary is the service provider.\n",
    "#### Passive adversary (Honest but curious).\n",
    "The adversary is in possess of\n",
    "the logs of all the queries made by users to the service,\n",
    "containing queries contents and metadata.\n",
    "#### Global adversary:\n",
    "the adversary view is the whole network (i.e all grids\n",
    "covered by the service).\n",
    "#### Computational power:\n",
    "the adversary is bounded by polynomial time complexity.\n",
    "#### Background knowledge:\n",
    "The adversary has some background knowledge on a subset of users, for example\n",
    "she knows the mapping between IP address and names.\n",
    "She has also access to side information on users, for example she\n",
    "can observe their social network profiles.\n",
    "#### Adversarial Goal:\n",
    "Gain knowledge about daily similarities in users trajectories, such that\n",
    "to identify users through co-locations information.\n",
    "For example, if the adversary learns that on day 5 user 1, Bob, and user 2,\n",
    "unknown, had very similar trajectories, and she furthermore knows Bob name and surname\n",
    "(thus having access to a public profile for this user on a social network), if\n",
    "Bob shares information about co-location (for example being at lunch\n",
    "with his friend Alice), then the adversary can infer that user 2 is Alice.\n",
    "(From https://ieeexplore.ieee.org/document/8228621)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14110    0.98.248.97  46.546740  6.577377   11.516781      cafeteria       63   \n",
      "14111    0.98.248.97  46.546740  6.577377   11.516781     restaurant       63   \n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14114    0.98.248.97  46.546740  6.577377   34.866475      cafeteria       63   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4151   97.138.146.97  46.520518  6.568483  447.896803            gym       22   \n",
      "4152   97.138.146.97  46.520518  6.568483  465.134875    supermarket       22   \n",
      "4153   97.138.146.97  46.503018  6.642813  465.134875            bar       10   \n",
      "4154   97.138.146.97  46.501978  6.645289  465.134875            gym       10   \n",
      "4155   97.138.146.97  46.521116  6.640636  465.134875           dojo       40   \n",
      "\n",
      "       day  time      daytime  filter  user_id  \n",
      "14110    1    11    2.Morning   False        0  \n",
      "14111    1    11    2.Morning   False        0  \n",
      "14112    1    18    4.Evening    True        0  \n",
      "14113    1    18    4.Evening    True        0  \n",
      "14114    2    10    2.Morning   False        0  \n",
      "...    ...   ...          ...     ...      ...  \n",
      "4151    19    15  3.Afternoon   False      199  \n",
      "4152    20     9    2.Morning   False      199  \n",
      "4153    20     9    2.Morning   False      199  \n",
      "4154    20     9    2.Morning   False      199  \n",
      "4155    20     9    2.Morning   False      199  \n",
      "\n",
      "[20443 rows x 11 columns]\n",
      "131.210.249.71 similar to 37.238.140.76 on day 1\n",
      "135.104.79.52 similar to 233.228.129.122 on day 1\n",
      "113.244.164.228 similar to 126.107.209.19 on day 3\n",
      "113.244.164.228 similar to 126.107.209.19 on day 8\n",
      "131.210.249.71 similar to 245.191.255.251 on day 8\n",
      "131.210.249.71 similar to 37.238.140.76 on day 8\n",
      "245.191.255.251 similar to 37.238.140.76 on day 8\n",
      "131.210.249.71 similar to 245.191.255.251 on day 10\n",
      "113.244.164.228 similar to 126.107.209.19 on day 11\n",
      "131.210.249.71 similar to 245.191.255.251 on day 11\n",
      "131.210.249.71 similar to 245.191.255.251 on day 12\n",
      "131.210.249.71 similar to 37.238.140.76 on day 15\n",
      "131.210.249.71 similar to 245.191.255.251 on day 16\n",
      "113.244.164.228 similar to 126.107.209.19 on day 17\n",
      "131.210.249.71 similar to 37.238.140.76 on day 17\n",
      "135.104.79.52 similar to 233.228.129.122 on day 18\n",
      "245.191.255.251 similar to 37.238.140.76 on day 18\n",
      "131.210.249.71 similar to 37.238.140.76 on day 19\n"
     ]
    }
   ],
   "source": [
    "def generate_user_id(user):\n",
    "    return users.index(user)\n",
    "\n",
    "queries_df['user_id'] = np.vectorize(generate_user_id)(queries_df['ip_address'])\n",
    "print(queries_df)\n",
    "users_trajectories = []\n",
    "cells = queries_df['cell_id'].drop_duplicates().tolist()\n",
    "data = []\n",
    "for day in days:\n",
    "    #find longest trajectory\n",
    "    max_points = queries_df[queries_df['day'] == day]\\\n",
    "        .groupby('ip_address').size().agg(['max'])\n",
    "    max_points = max_points.to_numpy()[0]\n",
    "    trajectories_per_user = []\n",
    "    ticks = []\n",
    "    for user in users:\n",
    "        serie = queries_df[\n",
    "            (queries_df['ip_address'] == user)\n",
    "            &\n",
    "            (queries_df['day'] == day)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        if len(x) > max_points/2:\n",
    "            ticks.append(str(users.index(user))) #user id\n",
    "            while len(x) < max_points:\n",
    "                #fill trajectory with last known position\n",
    "                x.append(x[-1])\n",
    "                y.append(y[-1])\n",
    "            assert len(x) == max_points\n",
    "            assert len(y) == max_points\n",
    "            trajectory = np.zeros((max_points,2))\n",
    "            trajectory[:,0] = x\n",
    "            trajectory[:,1] = y\n",
    "            trajectories_per_user.append(trajectory)\n",
    "    if len(trajectories_per_user) >= 2:\n",
    "        dist_m = compute_distance_matrix(trajectories_per_user)\n",
    "        km = 0.1 #100 meter difference between trajectories\n",
    "        km_per_radians = 6731.0\n",
    "        labels = clustering_by_dbscan(dist_m,eps=km/km_per_radians)\n",
    "        for i in range(0,len(labels)):\n",
    "            for j in range(i + 1, len(labels)-1):\n",
    "                if labels[i] == labels[j] and labels[i] != -1:\n",
    "                    print(f'{users[i]} similar to {users[j]} on day {day}')\n",
    "                    data.append( (users[i], users[j], day))\n",
    "clusterized_users = pd.DataFrame(data, columns=[\"user_A\", \"user_B\", \"day\"])\n",
    "clusterized_users = clusterized_users.sort_values(by=['user_A','day','user_B'])\n",
    "clusterized_users.to_csv('users_trajectories_similarities.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Infer Users' Top Locations - Identity linkage attack\n",
    "\n",
    "What we are trying to do here is: for each user, for each daytime group,\n",
    "we want to cluster their locations. By doing so, we can identify,\n",
    "for example, their top locations. Their house would be for\n",
    "example the centroid of the cluster of locations with most points in daytime group = home.\n",
    "\n",
    "### Adversarial Model\n",
    "The adversary is the service provider.\n",
    "#### Passive adversary (Honest but curious).\n",
    "The adversary is in possess of\n",
    "the logs of all the queries made by users to the service, containing queries contents\n",
    "and metadata.\n",
    "#### Global adversary:\n",
    "the adversary view is the whole network (i.e all grids\n",
    "covered by the service).\n",
    "#### Computational power:\n",
    "the adversary is bounded by polynomial time complexity.\n",
    "#### Background knowledge:\n",
    "If the adversary has some background knowledge on users, for example\n",
    "she knows the mapping between IP address and names, an identity linkage attack\n",
    "is possible.\n",
    "#### Adversarial Goal:\n",
    "Infer users' top locations (i.e home, workplace,\n",
    "frequent places visited during leisure time) to later be able\n",
    "to re-identify users (identity inference attack)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address   home_lat  home_lon   work_lat  work_lon  leisure_lan  \\\n",
      "0        0.98.248.97  46.510700  6.628843  46.510700  6.628843    46.510700   \n",
      "1      10.229.150.53  46.562529  6.596980  46.546377  6.575353    46.562529   \n",
      "2      100.255.65.73  46.549880  6.609449  46.527792  6.597571    46.555607   \n",
      "3    101.193.212.180  46.537596  6.627838  46.535992  6.622526          NaN   \n",
      "4     103.107.27.105  46.539250  6.629559  46.546377  6.575353    46.539250   \n",
      "..               ...        ...       ...        ...       ...          ...   \n",
      "195   94.220.204.193  46.557610  6.563681  46.567488  6.622811    46.557039   \n",
      "196    94.223.68.192  46.538914  6.604344  46.527792  6.597571    46.536827   \n",
      "197   95.146.245.203  46.562945  6.584247  46.521844  6.582789    46.562945   \n",
      "198   96.128.153.246  46.560172  6.648720  46.525781  6.600312    46.557310   \n",
      "199    97.138.146.97  46.517607  6.560419  46.520518  6.568483    46.520518   \n",
      "\n",
      "     leisure_lon  \n",
      "0       6.628843  \n",
      "1       6.596980  \n",
      "2       6.605922  \n",
      "3            NaN  \n",
      "4       6.629559  \n",
      "..           ...  \n",
      "195     6.569707  \n",
      "196     6.600886  \n",
      "197     6.584247  \n",
      "198     6.643756  \n",
      "199     6.568483  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm -r ./location_clusters\n",
    "!mkdir ./location_clusters\n",
    "\n",
    "daytime = {}\n",
    "daytime['home'] = ['1.Early', '5.Night']\n",
    "daytime['work'] = ['2.Morning', '3.Afternoon']\n",
    "daytime['leisure'] = ['4.Evening']\n",
    "\n",
    "data = []\n",
    "for user in users:\n",
    "    entry = []\n",
    "    entry.append(user)\n",
    "    for dt in daytime.keys():\n",
    "        for moment in daytime[dt]:\n",
    "            serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['daytime'] == moment)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        n = len(x)\n",
    "        if n > 2:\n",
    "            coords = np.zeros((n,2))\n",
    "            coords[:,0] = x\n",
    "            coords[:,1] = y\n",
    "\n",
    "            #convert to randians\n",
    "            coords = np.radians(coords)\n",
    "            km = 0.01 #10 meter accuracy\n",
    "            km_per_radians = 6731.0\n",
    "            db = DBSCAN(eps=km/km_per_radians, min_samples=2, algorithm='ball_tree', metric='haversine').fit(coords)\n",
    "            fig = plt.figure()\n",
    "            fig.set_size_inches(10,8)\n",
    "            plt.scatter(x,y,c=db.labels_)\n",
    "            plt.savefig(f\"./location_clusters/{user}_{dt}.png\")\n",
    "            plt.close()\n",
    "\n",
    "            clusters_noise = np.array(db.labels_)\n",
    "            clusters = np.array([c for c in clusters_noise if c >= 0])\n",
    "            count = np.bincount(clusters)\n",
    "            top_cluster = clusters[np.argmax(count)]\n",
    "            x_top = []\n",
    "            y_top = []\n",
    "            for i in range(0,len(clusters_noise)):\n",
    "                if clusters_noise[i] == top_cluster:\n",
    "                    x_top.append(x[i])\n",
    "                    y_top.append(y[i])\n",
    "\n",
    "            lat = np.array(x_top).mean()\n",
    "            lon = np.array(y_top).mean()\n",
    "\n",
    "            entry.append(lat)\n",
    "            entry.append(lon)\n",
    "    data.append(entry)\n",
    "top_loc = pd.DataFrame(data, columns=\n",
    "                       ['ip_address', 'home_lat','home_lon','work_lat','work_lon', 'leisure_lan', 'leisure_lon'])\n",
    "print(top_loc)\n",
    "top_loc.to_csv('top_locations.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}