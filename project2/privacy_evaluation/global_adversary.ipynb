{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from grid import location_to_cell_id\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Read Dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      poi_id  cell_id     poi_type        lat       lon\n",
      "0        307        1          bar  46.504486  6.559631\n",
      "1        331        1          bar  46.500259  6.554721\n",
      "2        578        1  supermarket  46.506017  6.551165\n",
      "3        897        1         club  46.504494  6.553889\n",
      "4        972        1  supermarket  46.502984  6.550519\n",
      "...      ...      ...          ...        ...       ...\n",
      "1055     372      100   restaurant  46.563852  6.648454\n",
      "1056     649      100          bar  46.564047  6.640250\n",
      "1057     730      100          gym  46.565961  6.642228\n",
      "1058     828      100         club  46.569177  6.642401\n",
      "1059     990      100          bar  46.565290  6.640855\n",
      "\n",
      "[1060 rows x 5 columns]\n",
      "           ip_address        lat       lon   timestamp poi_type_query\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria\n",
      "...               ...        ...       ...         ...            ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant\n",
      "\n",
      "[20443 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "pois_df = pd.read_csv('pois.csv', sep=' ')\n",
    "queries_df = pd.read_csv('queries.csv', sep=' ')\n",
    "\n",
    "print(pois_df)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ip_address        lat       lon   timestamp poi_type_query  cell_id\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria       45\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant       45\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant       76\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria       76\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria       45\n",
      "...               ...        ...       ...         ...            ...      ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket       38\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket       38\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym       38\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket       38\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant       38\n",
      "\n",
      "[20443 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extract cell_id from which query happened\n",
    "def get_cell_id(row):\n",
    "    return location_to_cell_id(row['lat'], row['lon'])\n",
    "\n",
    "queries_df['cell_id'] = queries_df.apply(lambda row: get_cell_id(row), axis=1)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14110    0.98.248.97  46.546740  6.577377   11.516781      cafeteria       63   \n",
      "14111    0.98.248.97  46.546740  6.577377   11.516781     restaurant       63   \n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14114    0.98.248.97  46.546740  6.577377   34.866475      cafeteria       63   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4151   97.138.146.97  46.520518  6.568483  447.896803            gym       22   \n",
      "4152   97.138.146.97  46.520518  6.568483  465.134875    supermarket       22   \n",
      "4153   97.138.146.97  46.503018  6.642813  465.134875            bar       10   \n",
      "4154   97.138.146.97  46.501978  6.645289  465.134875            gym       10   \n",
      "4155   97.138.146.97  46.521116  6.640636  465.134875           dojo       40   \n",
      "\n",
      "       day  time      daytime  \n",
      "14110    1    11    2.Morning  \n",
      "14111    1    11    2.Morning  \n",
      "14112    1    18    4.Evening  \n",
      "14113    1    18    4.Evening  \n",
      "14114    2    10    2.Morning  \n",
      "...    ...   ...          ...  \n",
      "4151    19    15  3.Afternoon  \n",
      "4152    20     9    2.Morning  \n",
      "4153    20     9    2.Morning  \n",
      "4154    20     9    2.Morning  \n",
      "4155    20     9    2.Morning  \n",
      "\n",
      "[20443 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Get day of the query and time\n",
    "def get_day(row):\n",
    "    return ceil(row['timestamp'] / 24)\n",
    "\n",
    "def get_hour_of_day(row):\n",
    "    return int(row['timestamp'] % 24)\n",
    "\n",
    "queries_df['day'] = queries_df.apply(lambda row: get_day(row), axis=1)\n",
    "queries_df['time'] = queries_df.apply(lambda row: get_hour_of_day(row), axis=1)\n",
    "\n",
    "#Get daytime\n",
    "def get_daytime(row):\n",
    "    time = row['time']\n",
    "    if (time >= 0 and time < 9):\n",
    "        return '1.Early'\n",
    "    if (time >= 9 and time < 12):\n",
    "        return '2.Morning'\n",
    "    if (time >= 12 and time < 17):\n",
    "        return '3.Afternoon'\n",
    "    if (time >= 17 and time < 20):\n",
    "        return '4.Evening'\n",
    "    if (time >= 20 and time <= 23):\n",
    "        return '5.Night'\n",
    "queries_df['daytime'] = queries_df.apply(lambda row: get_daytime(row), axis=1)\n",
    "queries_df = queries_df.sort_values(by=['ip_address', 'day', 'time'])\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ip_address      daytime  day  cell_id  count\n",
      "0       0.98.248.97    2.Morning    1       63      2\n",
      "1       0.98.248.97    4.Evening    1       18      2\n",
      "2       0.98.248.97    2.Morning    2       63      2\n",
      "3       0.98.248.97      5.Night    2       18      4\n",
      "4       0.98.248.97    2.Morning    3       63      2\n",
      "...             ...          ...  ...      ...    ...\n",
      "9672  97.138.146.97  3.Afternoon   19       22      2\n",
      "9673  97.138.146.97  3.Afternoon   19       53      2\n",
      "9674  97.138.146.97    2.Morning   20       10      2\n",
      "9675  97.138.146.97    2.Morning   20       22      1\n",
      "9676  97.138.146.97    2.Morning   20       40      1\n",
      "\n",
      "[9677 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm queries_grouped.csv\n",
    "queries_grouped = queries_df.groupby(['ip_address', 'daytime', 'day','cell_id'])\\\n",
    "    .size().sort_index(level=[0,2,1])\n",
    "#queries_grouped = queries_grouped.where(queries_grouped['count'] > 4).dropna()\n",
    "\n",
    "queries_grouped = queries_grouped.to_frame(name='count').reset_index()\n",
    "print(queries_grouped)\n",
    "queries_grouped.to_csv('queries_grouped.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "queries_grouped contains, for each ip, for each day and daytime,\n",
    "the number of queries launched from a certain cell_id.\n",
    "It could be useful for inferring movement patterns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'max_cell_daytime.csv': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm max_cell_daytime.csv\n",
    "queries_grouped_day_removed = queries_grouped.drop(['day'],axis = 1)\n",
    "max_cell_daytime = queries_grouped_day_removed.groupby(['ip_address','daytime'])\\\n",
    "    .agg(['max'])\n",
    "max_cell_daytime.to_csv('max_cell_daytime.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "max_cell_daytime contains, for each ip, for each daytime, the cell\n",
    "from which most queries have been made.\n",
    "It could be useful to individuate home/work cell id in grid.\n",
    "The assumption here is that users are on average\n",
    "habitudinary people, such that each day, for each daytime,\n",
    "the set of cells does not vary too much."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#reset the multi index manually\n",
    "#i.e just removed first two rows from stats2 and created header\n",
    "\n",
    "!sed -i -e 1,3d max_cell_daytime.csv\n",
    "!echo -e \"ip_address,daytime,cell_id,count\\n$(cat max_cell_daytime.csv)\" > max_cell_daytime.csv\n",
    "\n",
    "max_cell_daytime = pd.read_csv('max_cell_daytime.csv', sep=',', header='infer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14116    0.98.248.97  46.510700  6.628843   44.419632     restaurant       18   \n",
      "14117    0.98.248.97  46.510700  6.628843   44.419632           dojo       18   \n",
      "14118    0.98.248.97  46.513656  6.629130   44.484873    supermarket       18   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4145   97.138.146.97  46.535919  6.575488  420.080602     restaurant       53   \n",
      "4146   97.138.146.97  46.520518  6.568483  426.834979            gym       22   \n",
      "4147   97.138.146.97  46.520518  6.568483  426.834979           dojo       22   \n",
      "4148   97.138.146.97  46.535919  6.575488  444.091082      cafeteria       53   \n",
      "4149   97.138.146.97  46.535919  6.575488  444.091082     restaurant       53   \n",
      "\n",
      "       day  time      daytime  \n",
      "14112    1    18    4.Evening  \n",
      "14113    1    18    4.Evening  \n",
      "14116    2    20      5.Night  \n",
      "14117    2    20      5.Night  \n",
      "14118    2    20      5.Night  \n",
      "...    ...   ...          ...  \n",
      "4145    18    12  3.Afternoon  \n",
      "4146    18    18    4.Evening  \n",
      "4147    18    18    4.Evening  \n",
      "4148    19    12  3.Afternoon  \n",
      "4149    19    12  3.Afternoon  \n",
      "\n",
      "[15127 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "! rm queries_filtered.csv\n",
    "class Filter:\n",
    "    def __init__(self, max_cell_daytime):\n",
    "        self.max_cell_daytime = max_cell_daytime\n",
    "\n",
    "    def filter_locations(self, user, daytime, cell_id):\n",
    "        max_cell_daytime = self.max_cell_daytime\n",
    "        cell = max_cell_daytime.loc[(max_cell_daytime['ip_address'] == user) & (max_cell_daytime['daytime'] == daytime)]['cell_id'].to_numpy()[0]\n",
    "        if cell_id != cell:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "custom_filter = Filter(max_cell_daytime)\n",
    "queries_df['filter'] = np.vectorize(custom_filter.filter_locations)(queries_df['ip_address'], queries_df['daytime'], queries_df['cell_id'])\n",
    "queries_df_filtered = queries_df[queries_df['filter'] == True].drop(columns=['filter'])\\\n",
    "    .sort_values(by=['ip_address', 'day', 'time', 'daytime'], axis=0)\n",
    "print(queries_df_filtered)\n",
    "queries_df_filtered.to_csv('queries_filtered.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "filtering queries with locations from cell_id which\n",
    "turned out to be the most interesting cells, for each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                user  day                                            pattern\n",
      "0        0.98.248.97    1  {'lat': 46.54673993140806, 'lon': 6.5773774300...\n",
      "1        0.98.248.97    1  {'lat': 46.54673993140806, 'lon': 6.5773774300...\n",
      "2        0.98.248.97    1  {'lat': 46.510699517190126, 'lon': 6.628843215...\n",
      "3        0.98.248.97    1  {'lat': 46.510699517190126, 'lon': 6.628843215...\n",
      "4        0.98.248.97    2  {'lat': 46.54673993140806, 'lon': 6.5773774300...\n",
      "...              ...  ...                                                ...\n",
      "20438  97.138.146.97   19  {'lat': 46.5205175117895, 'lon': 6.56848319255...\n",
      "20439  97.138.146.97   20  {'lat': 46.5205175117895, 'lon': 6.56848319255...\n",
      "20440  97.138.146.97   20  {'lat': 46.50301841141297, 'lon': 6.6428132570...\n",
      "20441  97.138.146.97   20  {'lat': 46.50197837744923, 'lon': 6.6452885814...\n",
      "20442  97.138.146.97   20  {'lat': 46.521115584387886, 'lon': 6.640635736...\n",
      "\n",
      "[20443 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import make_dataclass\n",
    "pattern = make_dataclass(\"pattern\", [(\"lat\", np.float32), (\"lon\", np.float32), ('time', int), (\"pois\",str)])\n",
    "trace = make_dataclass(\"trace\", [(\"user\", str), (\"day\", int), (\"pattern\", pattern)])\n",
    "traces = []\n",
    "users = queries_df['ip_address'].drop_duplicates().tolist()\n",
    "days = [_ for _ in range(1,21)]\n",
    "\n",
    "for user in users:\n",
    "    for day in days:\n",
    "        serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['day'] == day)][['lat','lon','time','poi_type_query']]\n",
    "        for row in serie.itertuples():\n",
    "            pat = pattern(row[1], row[2], row[3], row[4])\n",
    "            tr = trace(user, day, pat)\n",
    "            traces.append(tr)\n",
    "\n",
    "traces_df = pd.DataFrame(traces)\n",
    "print(traces_df)\n",
    "traces_df.to_csv('traces.csv', sep=',', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "not so useful stuff..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Trajectory study\n",
    "\n",
    "### 3.1\n",
    "Here we try to study, for each user, on a daily basis, their\n",
    "trajectories and how they differ from day to day. For\n",
    "computing the similarity, Frechet distance is used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: similaritymeasures in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (0.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (from similaritymeasures) (1.20.2)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (from similaritymeasures) (1.6.3)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\r\n",
      "You should consider upgrading via the '/home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install similaritymeasures\n",
    "!rm -r ./daily_trajectories\n",
    "!mkdir ./daily_trajectories\n",
    "\n",
    "from similaritymeasures import frechet_dist\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "users = queries_df['ip_address'].drop_duplicates().tolist()\n",
    "days = [_ for _ in range(1,21)]\n",
    "user_trajectories_per_day = []\n",
    "user_trajectories_cluster = []\n",
    "\n",
    "def compute_distance_matrix(trajectories):\n",
    "    n = len(trajectories)\n",
    "    dist_m = np.zeros((n, n))\n",
    "    for i in range(n - 1):\n",
    "        p = trajectories[i]\n",
    "        for j in range(i, n):\n",
    "            q = trajectories[j]\n",
    "            dist_m[i, j] = frechet_dist(np.radians(p), np.radians(q))\n",
    "            dist_m[j, i] = dist_m[i, j]\n",
    "    return dist_m\n",
    "\n",
    "def clustering_by_dbscan(distance_matrix, eps=100):\n",
    "    \"\"\"\n",
    "    :param eps: unit m for Frechet distance, m^2 for Area\n",
    "    \"\"\"\n",
    "    db = DBSCAN(eps=eps, min_samples=1, metric='precomputed').fit(distance_matrix)\n",
    "    return db.labels_\n",
    "\n",
    "for user in users:\n",
    "    max_points = queries_df[(queries_df['ip_address'] == user)].groupby('day').size().agg(['max'])\n",
    "    max_points = max_points.to_numpy()[0]\n",
    "    trajectories_per_day = []\n",
    "    ticks = []\n",
    "    for day in days:\n",
    "        serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['day'] == day)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        if len(x) != 0 and len(y) != 0:\n",
    "            ticks.append(str(day))\n",
    "            while len(x) < max_points:\n",
    "                #fill trajectory with last known position\n",
    "                x.append(x[-1])\n",
    "                y.append(y[-1])\n",
    "            assert len(x) == max_points\n",
    "            assert len(y) == max_points\n",
    "            trajectory = np.zeros((max_points,2))\n",
    "            trajectory[:,0] = x\n",
    "            trajectory[:,1] = y\n",
    "            trajectories_per_day.append(trajectory)\n",
    "    dist_m = compute_distance_matrix(trajectories_per_day)\n",
    "    sns.set(font_scale = 2)\n",
    "    fig = plt.figure(figsize=(42,21))\n",
    "    ax = sns.heatmap(dist_m, linewidths=1,\n",
    "                     linecolor='white',\n",
    "                     xticklabels=ticks,\n",
    "                     yticklabels=ticks)\n",
    "    plt.savefig(f'./daily_trajectories/{user}-matrix.png')\n",
    "    plt.close()\n",
    "    user_trajectories_per_day.append(trajectories_per_day)\n",
    "\n",
    "    labels = clustering_by_dbscan(dist_m)\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    assert n_clusters_ == 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results: User trajectories\n",
    "are almost the same on a daily basis. In order to validate the results,\n",
    "we used dbscan clustering and checked if the number of clusters\n",
    "of trajectories per user was 1.\n",
    "\n",
    "### 3.2\n",
    "Here we compare users trajectory along all the days of measurements to see\n",
    "if some users have commons patterns. In order to reduce the\n",
    "number of users compared, we grouped them by cells."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "users_trajectories = []\n",
    "cells = queries_df['cell_id'].drop_duplicates().tolist()\n",
    "\n",
    "!rm -r ./users_trajectories\n",
    "!mkdir ./users_trajectories\n",
    "def compute_distance_matrix(trajectories):\n",
    "    n = len(trajectories)\n",
    "    dist_m = np.zeros((n, n))\n",
    "    for i in range(n - 1):\n",
    "        p = trajectories[i]\n",
    "        for j in range(i, n):\n",
    "            q = trajectories[j]\n",
    "            dist_m[i, j] = frechet_dist(np.radians(p), np.radians(q))\n",
    "            dist_m[j, i] = dist_m[i, j]\n",
    "    return dist_m\n",
    "\n",
    "def clustering_by_dbscan(distance_matrix, eps=100):\n",
    "    \"\"\"\n",
    "    :param eps: unit m for Frechet distance, m^2 for Area\n",
    "    \"\"\"\n",
    "    db = DBSCAN(eps=eps, min_samples=1, metric='precomputed').fit(distance_matrix)\n",
    "    return db.labels_\n",
    "\n",
    "for cell in cells:\n",
    "    #find longest trajectory\n",
    "    max_points = queries_df[(queries_df['cell_id'] == cell)]\\\n",
    "        .groupby('ip_address').size().agg(['max'])\n",
    "    max_points = max_points.to_numpy()[0]\n",
    "    trajectories_per_user = []\n",
    "    ticks = []\n",
    "    for user in users:\n",
    "        serie = queries_df[\n",
    "            (queries_df['ip_address'] == user)\n",
    "            &\n",
    "            (queries_df['cell_id'] == cell)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        if len(x) != 0 and len(y) != 0:\n",
    "            ticks.append(str(user))\n",
    "            while len(x) < max_points:\n",
    "                #fill trajectory with last known position\n",
    "                x.append(x[-1])\n",
    "                y.append(y[-1])\n",
    "            assert len(x) == max_points\n",
    "            assert len(y) == max_points\n",
    "            trajectory = np.zeros((max_points,2))\n",
    "            trajectory[:,0] = x\n",
    "            trajectory[:,1] = y\n",
    "            trajectories_per_user.append(trajectory)\n",
    "    if len(trajectories_per_user) >= 2:\n",
    "        dist_m = compute_distance_matrix(trajectories_per_user)\n",
    "        sns.set(font_scale = 2)\n",
    "        fig = plt.figure(figsize=(42,21))\n",
    "        ax = sns.heatmap(dist_m,\n",
    "                         linewidths=2,\n",
    "                         linecolor='white',\n",
    "                         xticklabels=ticks,\n",
    "                         yticklabels=ticks)\n",
    "        plt.savefig(f'./users_trajectories/{cell}-matrix.png')\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Infer Users' Top Locations\n",
    "\n",
    "What we are trying to do here is: for each user, for each daytime group,\n",
    "we want to cluster their locations. By doing so, we can identify,\n",
    "for example, their top locations. Their house would be for\n",
    "example the centroid of the cluster of locations with most points in daytime group = home."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                user   home_lat  home_lon   work_lat  work_lon  leisure_lan  \\\n",
      "0        0.98.248.97  46.511046  6.628705  46.510700  6.628843    46.510377   \n",
      "1      10.229.150.53  46.558934  6.595539  46.546377  6.575353    46.558531   \n",
      "2      100.255.65.73  46.549811  6.609473  46.527792  6.597571    46.554351   \n",
      "3    101.193.212.180  46.537625  6.626529  46.536221  6.623285          NaN   \n",
      "4     103.107.27.105  46.537512  6.628398  46.546377  6.575353    46.537842   \n",
      "..               ...        ...       ...        ...       ...          ...   \n",
      "195   94.220.204.193  46.559173  6.563487  46.567488  6.622811    46.556959   \n",
      "196    94.223.68.192  46.538374  6.603719  46.527792  6.597571    46.536978   \n",
      "197   95.146.245.203  46.560926  6.584634  46.521844  6.582789    46.560506   \n",
      "198   96.128.153.246  46.560381  6.643574  46.525781  6.600312    46.560920   \n",
      "199    97.138.146.97  46.517599  6.564685  46.520518  6.568483    46.519935   \n",
      "\n",
      "     leisure_lon  \n",
      "0       6.628752  \n",
      "1       6.599282  \n",
      "2       6.606667  \n",
      "3            NaN  \n",
      "4       6.627058  \n",
      "..           ...  \n",
      "195     6.569401  \n",
      "196     6.601452  \n",
      "197     6.584087  \n",
      "198     6.644625  \n",
      "199     6.566870  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm -r ./location_clusters\n",
    "!mkdir ./location_clusters\n",
    "\n",
    "daytime = {}\n",
    "daytime['home'] = ['1.Early', '5.Night']\n",
    "daytime['work'] = ['2.Morning', '3.Afternoon']\n",
    "daytime['leisure'] = ['4.Evening']\n",
    "\n",
    "data = []\n",
    "for user in users:\n",
    "    entry = []\n",
    "    entry.append(user)\n",
    "    for dt in daytime.keys():\n",
    "        for moment in daytime[dt]:\n",
    "            serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['daytime'] == moment)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        n = len(x)\n",
    "        if n > 2:\n",
    "            coords = np.zeros((n,2))\n",
    "            coords[:,0] = x\n",
    "            coords[:,1] = y\n",
    "\n",
    "            #convert to randians\n",
    "            coords = np.radians(coords)\n",
    "            km = 1\n",
    "            km_per_radians = 6731.0\n",
    "            db = DBSCAN(eps=km/km_per_radians, min_samples=2, algorithm='ball_tree', metric='haversine').fit(coords)\n",
    "            fig = plt.figure()\n",
    "            fig.set_size_inches(10,8)\n",
    "            plt.scatter(x,y,c=db.labels_)\n",
    "            plt.savefig(f\"./location_clusters/{user}_{dt}.png\")\n",
    "            plt.close()\n",
    "\n",
    "            clusters_noise = np.array(db.labels_)\n",
    "            clusters = np.array([c for c in clusters_noise if c >= 0])\n",
    "            count = np.bincount(clusters)\n",
    "            top_cluster = clusters[np.argmax(count)]\n",
    "            x_top = []\n",
    "            y_top = []\n",
    "            for i in range(0,len(clusters_noise)):\n",
    "                if clusters_noise[i] == top_cluster:\n",
    "                    x_top.append(x[i])\n",
    "                    y_top.append(y[i])\n",
    "\n",
    "            lat = np.array(x_top).mean()\n",
    "            lon = np.array(y_top).mean()\n",
    "\n",
    "            entry.append(lat)\n",
    "            entry.append(lon)\n",
    "    data.append(entry)\n",
    "top_loc = pd.DataFrame(data, columns=\n",
    "                       ['ip_address', 'home_lat','home_lon','work_lat','work_lon', 'leisure_lan', 'leisure_lon'])\n",
    "print(top_loc)\n",
    "top_loc.to_csv('top_locations.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}