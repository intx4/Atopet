{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from grid import location_to_cell_id\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Read Dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      poi_id  cell_id     poi_type        lat       lon\n",
      "0        307        1          bar  46.504486  6.559631\n",
      "1        331        1          bar  46.500259  6.554721\n",
      "2        578        1  supermarket  46.506017  6.551165\n",
      "3        897        1         club  46.504494  6.553889\n",
      "4        972        1  supermarket  46.502984  6.550519\n",
      "...      ...      ...          ...        ...       ...\n",
      "1055     372      100   restaurant  46.563852  6.648454\n",
      "1056     649      100          bar  46.564047  6.640250\n",
      "1057     730      100          gym  46.565961  6.642228\n",
      "1058     828      100         club  46.569177  6.642401\n",
      "1059     990      100          bar  46.565290  6.640855\n",
      "\n",
      "[1060 rows x 5 columns]\n",
      "           ip_address        lat       lon   timestamp poi_type_query\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria\n",
      "...               ...        ...       ...         ...            ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant\n",
      "\n",
      "[20443 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "pois_df = pd.read_csv('pois.csv', sep=' ')\n",
    "queries_df = pd.read_csv('queries.csv', sep=' ')\n",
    "\n",
    "print(pois_df)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ip_address        lat       lon   timestamp poi_type_query  cell_id\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria       45\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant       45\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant       76\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria       76\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria       45\n",
      "...               ...        ...       ...         ...            ...      ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket       38\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket       38\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym       38\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket       38\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant       38\n",
      "\n",
      "[20443 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extract cell_id from which query happened\n",
    "def get_cell_id(row):\n",
    "    return location_to_cell_id(row['lat'], row['lon'])\n",
    "\n",
    "queries_df['cell_id'] = queries_df.apply(lambda row: get_cell_id(row), axis=1)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14110    0.98.248.97  46.546740  6.577377   11.516781      cafeteria       63   \n",
      "14111    0.98.248.97  46.546740  6.577377   11.516781     restaurant       63   \n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14114    0.98.248.97  46.546740  6.577377   34.866475      cafeteria       63   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4151   97.138.146.97  46.520518  6.568483  447.896803            gym       22   \n",
      "4152   97.138.146.97  46.520518  6.568483  465.134875    supermarket       22   \n",
      "4153   97.138.146.97  46.503018  6.642813  465.134875            bar       10   \n",
      "4154   97.138.146.97  46.501978  6.645289  465.134875            gym       10   \n",
      "4155   97.138.146.97  46.521116  6.640636  465.134875           dojo       40   \n",
      "\n",
      "       day  time      daytime  \n",
      "14110    1    11    2.Morning  \n",
      "14111    1    11    2.Morning  \n",
      "14112    1    18    4.Evening  \n",
      "14113    1    18    4.Evening  \n",
      "14114    2    10    2.Morning  \n",
      "...    ...   ...          ...  \n",
      "4151    19    15  3.Afternoon  \n",
      "4152    20     9    2.Morning  \n",
      "4153    20     9    2.Morning  \n",
      "4154    20     9    2.Morning  \n",
      "4155    20     9    2.Morning  \n",
      "\n",
      "[20443 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Get day of the query and time\n",
    "def get_day(row):\n",
    "    return ceil(row['timestamp'] / 24)\n",
    "\n",
    "def get_hour_of_day(row):\n",
    "    return int(row['timestamp'] % 24)\n",
    "\n",
    "queries_df['day'] = queries_df.apply(lambda row: get_day(row), axis=1)\n",
    "queries_df['time'] = queries_df.apply(lambda row: get_hour_of_day(row), axis=1)\n",
    "\n",
    "#Get daytime\n",
    "def get_daytime(row):\n",
    "    time = row['time']\n",
    "    if (time >= 0 and time < 9):\n",
    "        return '1.Early'\n",
    "    if (time >= 9 and time < 12):\n",
    "        return '2.Morning'\n",
    "    if (time >= 12 and time < 17):\n",
    "        return '3.Afternoon'\n",
    "    if (time >= 17 and time < 20):\n",
    "        return '4.Evening'\n",
    "    if (time >= 20 and time <= 23):\n",
    "        return '5.Night'\n",
    "queries_df['daytime'] = queries_df.apply(lambda row: get_daytime(row), axis=1)\n",
    "queries_df = queries_df.sort_values(by=['ip_address', 'day', 'time'])\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'queries_grouped.csv': No such file or directory\r\n",
      "         ip_address      daytime  day  cell_id  count\n",
      "0       0.98.248.97    2.Morning    1       63      2\n",
      "1       0.98.248.97    4.Evening    1       18      2\n",
      "2       0.98.248.97    2.Morning    2       63      2\n",
      "3       0.98.248.97      5.Night    2       18      4\n",
      "4       0.98.248.97    2.Morning    3       63      2\n",
      "...             ...          ...  ...      ...    ...\n",
      "9672  97.138.146.97  3.Afternoon   19       22      2\n",
      "9673  97.138.146.97  3.Afternoon   19       53      2\n",
      "9674  97.138.146.97    2.Morning   20       10      2\n",
      "9675  97.138.146.97    2.Morning   20       22      1\n",
      "9676  97.138.146.97    2.Morning   20       40      1\n",
      "\n",
      "[9677 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm queries_grouped.csv\n",
    "queries_grouped = queries_df.groupby(['ip_address', 'daytime', 'day','cell_id'])\\\n",
    "    .size().sort_index(level=[0,2,1])\n",
    "#queries_grouped = queries_grouped.where(queries_grouped['count'] > 4).dropna()\n",
    "\n",
    "queries_grouped = queries_grouped.to_frame(name='count').reset_index()\n",
    "print(queries_grouped)\n",
    "queries_grouped.to_csv('queries_grouped.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "queries_grouped contains, for each ip, for each day and daytime,\n",
    "the number of queries launched from a certain cell_id\n",
    "it could be useful for inferring movement patterns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "!rm max_cell_daytime.csv\n",
    "queries_grouped_day_removed = queries_grouped.drop(['day'],axis = 1)\n",
    "max_cell_daytime = queries_grouped_day_removed.groupby(['ip_address','daytime'])\\\n",
    "    .agg(['max'])\n",
    "max_cell_daytime.to_csv('max_cell_daytime.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "max_cell_daytime contains, for each ip, for each daytime, the cell\n",
    "from which most queries have been made.\n",
    "It could be useful to individuate home/work cell id in grid\n",
    "The assumption here is that users are on average\n",
    "habitudinary people, such that each day, for each daytime,\n",
    "the set of cells does not vary too much."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#reset the multi index manually\n",
    "#i.e just removed first two rows from stats2 and created header\n",
    "\n",
    "!sed -i -e 1,3d max_cell_daytime.csv\n",
    "!echo -e \"ip_address,daytime,cell_id,count\\n$(cat max_cell_daytime.csv)\" > max_cell_daytime.csv\n",
    "\n",
    "max_cell_daytime = pd.read_csv('max_cell_daytime.csv', sep=',', header='infer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'queries_filtered.csv': No such file or directory\r\n",
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14116    0.98.248.97  46.510700  6.628843   44.419632     restaurant       18   \n",
      "14117    0.98.248.97  46.510700  6.628843   44.419632           dojo       18   \n",
      "14118    0.98.248.97  46.513656  6.629130   44.484873    supermarket       18   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4145   97.138.146.97  46.535919  6.575488  420.080602     restaurant       53   \n",
      "4146   97.138.146.97  46.520518  6.568483  426.834979            gym       22   \n",
      "4147   97.138.146.97  46.520518  6.568483  426.834979           dojo       22   \n",
      "4148   97.138.146.97  46.535919  6.575488  444.091082      cafeteria       53   \n",
      "4149   97.138.146.97  46.535919  6.575488  444.091082     restaurant       53   \n",
      "\n",
      "       day  time      daytime  \n",
      "14112    1    18    4.Evening  \n",
      "14113    1    18    4.Evening  \n",
      "14116    2    20      5.Night  \n",
      "14117    2    20      5.Night  \n",
      "14118    2    20      5.Night  \n",
      "...    ...   ...          ...  \n",
      "4145    18    12  3.Afternoon  \n",
      "4146    18    18    4.Evening  \n",
      "4147    18    18    4.Evening  \n",
      "4148    19    12  3.Afternoon  \n",
      "4149    19    12  3.Afternoon  \n",
      "\n",
      "[15127 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "! rm queries_filtered.csv\n",
    "class Filter:\n",
    "    def __init__(self, max_cell_daytime):\n",
    "        self.max_cell_daytime = max_cell_daytime\n",
    "\n",
    "    def filter_locations(self, user, daytime, cell_id):\n",
    "        max_cell_daytime = self.max_cell_daytime\n",
    "        cell = max_cell_daytime.loc[(max_cell_daytime['ip_address'] == user) & (max_cell_daytime['daytime'] == daytime)]['cell_id'].to_numpy()[0]\n",
    "        if cell_id != cell:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "custom_filter = Filter(max_cell_daytime)\n",
    "queries_df['filter'] = np.vectorize(custom_filter.filter_locations)(queries_df['ip_address'], queries_df['daytime'], queries_df['cell_id'])\n",
    "queries_df_filtered = queries_df[queries_df['filter'] == True].drop(columns=['filter'])\\\n",
    "    .sort_values(by=['ip_address', 'day', 'time', 'daytime'], axis=0)\n",
    "print(queries_df_filtered)\n",
    "queries_df_filtered.to_csv('queries_filtered.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "filtering queries with locations from cell_id which\n",
    "turned out to be the most interesting cells, for each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import make_dataclass\n",
    "pattern = make_dataclass(\"pattern\", [(\"lat\", np.float32), (\"lon\", np.float32), ('time', int), (\"pois\",str)])\n",
    "trace = make_dataclass(\"trace\", [(\"user\", str), (\"day\", int), (\"pattern\", pattern)])\n",
    "traces = []\n",
    "users = queries_df['ip_address'].drop_duplicates().tolist()\n",
    "days = [_ for _ in range(1,21)]\n",
    "\n",
    "for user in users:\n",
    "    for day in days:\n",
    "        serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['day'] == day)][['lat','lon','time','poi_type_query']]\n",
    "        for row in serie.itertuples():\n",
    "            pat = pattern(row[1], row[2], row[3], row[4])\n",
    "            tr = trace(user, day, pat)\n",
    "            traces.append(tr)\n",
    "\n",
    "traces_df = pd.DataFrame(traces)\n",
    "print(traces_df)\n",
    "traces_df.to_csv('traces.csv', sep=',', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "not so useful stuff..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Trajectory study\n",
    "\n",
    "Here we try to study, for each user, on a daily basis, their\n",
    "trajectories and how they differ from day to day. For\n",
    "computing the similarity, Frechet distance is used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: similaritymeasures in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (0.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (from similaritymeasures) (1.20.2)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/lib/python3.8/site-packages (from similaritymeasures) (1.6.3)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\r\n",
      "You should consider upgrading via the '/home/intx/PycharmProjects/Privacy_Enhancing_Tech_Project/project2/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-95d9bd2308e5>:59: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=(40,20))\n"
     ]
    }
   ],
   "source": [
    "!pip install similaritymeasures\n",
    "!rm -r ./figures\n",
    "!mkdir ./figures\n",
    "\n",
    "from similaritymeasures import frechet_dist\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "users = queries_df['ip_address'].drop_duplicates().tolist()\n",
    "days = [_ for _ in range(1,21)]\n",
    "user_trajectories_per_day = []\n",
    "user_trajectories_cluster = []\n",
    "\n",
    "def compute_distance_matrix(trajectories):\n",
    "    n = len(trajectories)\n",
    "    dist_m = np.zeros((n, n))\n",
    "    for i in range(n - 1):\n",
    "        p = trajectories[i]\n",
    "        for j in range(i, n):\n",
    "            q = trajectories[j]\n",
    "            dist_m[i, j] = frechet_dist(p, q)\n",
    "            dist_m[j, i] = dist_m[i, j]\n",
    "    return dist_m\n",
    "\n",
    "def clustering_by_dbscan(distance_matrix, eps=100):\n",
    "    \"\"\"\n",
    "    :param eps: unit m for Frechet distance, m^2 for Area\n",
    "    \"\"\"\n",
    "    db = DBSCAN(eps=eps, min_samples=1, metric='precomputed').fit(distance_matrix)\n",
    "    return db.labels_\n",
    "\n",
    "for user in users:\n",
    "    max_points = queries_df[(queries_df['ip_address'] == user)].groupby('day').size().agg(['max'])\n",
    "    max_points = max_points.to_numpy()[0]\n",
    "    trajectories_per_day = []\n",
    "    d = []\n",
    "    for day in days:\n",
    "        serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['day'] == day)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        if len(x) != 0 and len(y) != 0:\n",
    "            d.append(str(day))\n",
    "            while len(x) < max_points:\n",
    "                #fill trajectory with last known position\n",
    "                x.append(x[-1])\n",
    "                y.append(y[-1])\n",
    "            assert len(x) == max_points\n",
    "            assert len(y) == max_points\n",
    "            trajectory = np.zeros((max_points,2))\n",
    "            trajectory[:,0] = x\n",
    "            trajectory[:,1] = y\n",
    "            trajectories_per_day.append(trajectory)\n",
    "    dist_m = compute_distance_matrix(trajectories_per_day)\n",
    "    sns.set(font_scale = 2)\n",
    "    fig = plt.figure(figsize=(40,20))\n",
    "    ax = sns.heatmap(dist_m, linewidths=1, linecolor='white')\n",
    "    plt.savefig(f'./figures/{user}-matrix.png')\n",
    "\n",
    "    user_trajectories_per_day.append(trajectories_per_day)\n",
    "\n",
    "    labels = clustering_by_dbscan(dist_m)\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    num_labels = set(labels)\n",
    "    assert len(num_labels) == 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results: User trajectories\n",
    "are almost the same on a daily basis. In order to validate the results,\n",
    "we used dbscan clustering and checked if the number of clusters\n",
    "of trajectories per user was 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}