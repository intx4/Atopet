{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from grid import location_to_cell_id\n",
    "from sqlalchemy import create_engine\n",
    "from math import ceil\n",
    "\n",
    "engine = create_engine('sqlite://', echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Read Dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      poi_id  cell_id     poi_type        lat       lon\n",
      "0        307        1          bar  46.504486  6.559631\n",
      "1        331        1          bar  46.500259  6.554721\n",
      "2        578        1  supermarket  46.506017  6.551165\n",
      "3        897        1         club  46.504494  6.553889\n",
      "4        972        1  supermarket  46.502984  6.550519\n",
      "...      ...      ...          ...        ...       ...\n",
      "1055     372      100   restaurant  46.563852  6.648454\n",
      "1056     649      100          bar  46.564047  6.640250\n",
      "1057     730      100          gym  46.565961  6.642228\n",
      "1058     828      100         club  46.569177  6.642401\n",
      "1059     990      100          bar  46.565290  6.640855\n",
      "\n",
      "[1060 rows x 5 columns]\n",
      "           ip_address        lat       lon   timestamp poi_type_query\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria\n",
      "...               ...        ...       ...         ...            ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant\n",
      "\n",
      "[20443 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "pois_df = pd.read_csv('pois.csv', sep=' ')\n",
    "queries_df = pd.read_csv('queries.csv', sep=' ')\n",
    "\n",
    "print(pois_df)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ip_address        lat       lon   timestamp poi_type_query  cell_id\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria       45\n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant       45\n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant       76\n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria       76\n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria       45\n",
      "...               ...        ...       ...         ...            ...      ...\n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket       38\n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket       38\n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym       38\n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket       38\n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant       38\n",
      "\n",
      "[20443 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extract cell_id from which query happened\n",
    "def get_cell_id(row):\n",
    "    return location_to_cell_id(row['lat'], row['lon'])\n",
    "\n",
    "queries_df['cell_id'] = queries_df.apply(lambda row: get_cell_id(row), axis=1)\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ip_address        lat       lon   timestamp poi_type_query  \\\n",
      "0      34.101.177.245  46.532942  6.591174   14.912448      cafeteria   \n",
      "1      34.101.177.245  46.532942  6.591174   14.912448     restaurant   \n",
      "2      34.101.177.245  46.550342  6.602852   18.024657     restaurant   \n",
      "3      34.101.177.245  46.550342  6.602852   18.024657      cafeteria   \n",
      "4      34.101.177.245  46.532942  6.591174   36.334539      cafeteria   \n",
      "...               ...        ...       ...         ...            ...   \n",
      "20438     11.173.13.2  46.524410  6.625246  449.159554    supermarket   \n",
      "20439     11.173.13.2  46.527363  6.628705  453.426750    supermarket   \n",
      "20440     11.173.13.2  46.527363  6.628705  453.426750            gym   \n",
      "20441     11.173.13.2  46.524410  6.625246  464.420041    supermarket   \n",
      "20442     11.173.13.2  46.527363  6.628705  464.420041     restaurant   \n",
      "\n",
      "       cell_id  day  time      daytime  \n",
      "0           45    1    14  3.Afternoon  \n",
      "1           45    1    14  3.Afternoon  \n",
      "2           76    1    18    4.Evening  \n",
      "3           76    1    18    4.Evening  \n",
      "4           45    2    12  3.Afternoon  \n",
      "...        ...  ...   ...          ...  \n",
      "20438       38   19    17    4.Evening  \n",
      "20439       38   19    21      5.Night  \n",
      "20440       38   19    21      5.Night  \n",
      "20441       38   20     8      1.Early  \n",
      "20442       38   20     8      1.Early  \n",
      "\n",
      "[20443 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Get day of the query and time\n",
    "def get_day(row):\n",
    "    return ceil(row['timestamp'] / 24)\n",
    "\n",
    "def get_hour_of_day(row):\n",
    "    return int(row['timestamp'] % 24)\n",
    "\n",
    "queries_df['day'] = queries_df.apply(lambda row: get_day(row), axis=1)\n",
    "queries_df['time'] = queries_df.apply(lambda row: get_hour_of_day(row), axis=1)\n",
    "\n",
    "#Get daytime\n",
    "def get_daytime(row):\n",
    "    time = row['time']\n",
    "    if (time >= 0 and time < 9):\n",
    "        return '1.Early'\n",
    "    if (time >= 9 and time < 12):\n",
    "        return '2.Morning'\n",
    "    if (time >= 12 and time < 17):\n",
    "        return '3.Afternoon'\n",
    "    if (time >= 17 and time < 20):\n",
    "        return '4.Evening'\n",
    "    if (time >= 20 and time <= 23):\n",
    "        return '5.Night'\n",
    "queries_df['daytime'] = queries_df.apply(lambda row: get_daytime(row), axis=1)\n",
    "\n",
    "print(queries_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ip_address      daytime  day  cell_id  count\n",
      "0       0.98.248.97    2.Morning    1       63      2\n",
      "1       0.98.248.97    4.Evening    1       18      2\n",
      "2       0.98.248.97    2.Morning    2       63      2\n",
      "3       0.98.248.97      5.Night    2       18      4\n",
      "4       0.98.248.97    2.Morning    3       63      2\n",
      "...             ...          ...  ...      ...    ...\n",
      "9672  97.138.146.97  3.Afternoon   19       22      2\n",
      "9673  97.138.146.97  3.Afternoon   19       53      2\n",
      "9674  97.138.146.97    2.Morning   20       10      2\n",
      "9675  97.138.146.97    2.Morning   20       22      1\n",
      "9676  97.138.146.97    2.Morning   20       40      1\n",
      "\n",
      "[9677 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "!rm stats1.csv\n",
    "queries_grouped = queries_df.groupby(['ip_address', 'daytime', 'day','cell_id'])\\\n",
    "    .size().sort_index(level=[0,2,1])\n",
    "#queries_grouped = queries_grouped.where(queries_grouped['count'] > 4).dropna()\n",
    "\n",
    "queries_grouped = queries_grouped.to_frame(name='count').reset_index()\n",
    "print(queries_grouped)\n",
    "queries_grouped.to_csv('stats1.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "queries_grouped contains, for each ip, for each day and daytime,\n",
    "the number of queries launched from a certain cell_id\n",
    "it could be useful for inferring movement patterns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "!rm stats2.csv\n",
    "queries_grouped_day_removed = queries_grouped.drop(['day'],axis = 1)\n",
    "max_cell_daytime = queries_grouped_day_removed.groupby(['ip_address','daytime'])\\\n",
    "    .agg(['max'])\n",
    "max_cell_daytime.to_csv('stats2.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "max_cell_daytime contains, for each ip, for each daytime, the cell\n",
    "from which most queries have been made.\n",
    "It could be useful to individuate home/work cell id in grid\n",
    "The assumption here is that users are on average\n",
    "habitudinary people, such that each day, for each daytime,\n",
    "the set of cells does not vary too much."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#reset the multi index manually\n",
    "#i.e just removed first two rows from stats2 and created header\n",
    "\n",
    "!sed -i -e 1,3d stats2.csv\n",
    "!echo -e \"ip_address,daytime,cell_id,count\\n$(cat stats2.csv)\" > stats2.csv\n",
    "\n",
    "max_cell_daytime = pd.read_csv('stats2.csv', sep=',', header='infer')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ip_address        lat       lon   timestamp poi_type_query  cell_id  \\\n",
      "14112    0.98.248.97  46.510700  6.628843   18.995261           dojo       18   \n",
      "14113    0.98.248.97  46.510700  6.628843   18.995261    supermarket       18   \n",
      "14116    0.98.248.97  46.510700  6.628843   44.419632     restaurant       18   \n",
      "14117    0.98.248.97  46.510700  6.628843   44.419632           dojo       18   \n",
      "14118    0.98.248.97  46.513656  6.629130   44.484873    supermarket       18   \n",
      "...              ...        ...       ...         ...            ...      ...   \n",
      "4145   97.138.146.97  46.535919  6.575488  420.080602     restaurant       53   \n",
      "4146   97.138.146.97  46.520518  6.568483  426.834979            gym       22   \n",
      "4147   97.138.146.97  46.520518  6.568483  426.834979           dojo       22   \n",
      "4148   97.138.146.97  46.535919  6.575488  444.091082      cafeteria       53   \n",
      "4149   97.138.146.97  46.535919  6.575488  444.091082     restaurant       53   \n",
      "\n",
      "       day  time      daytime  \n",
      "14112    1    18    4.Evening  \n",
      "14113    1    18    4.Evening  \n",
      "14116    2    20      5.Night  \n",
      "14117    2    20      5.Night  \n",
      "14118    2    20      5.Night  \n",
      "...    ...   ...          ...  \n",
      "4145    18    12  3.Afternoon  \n",
      "4146    18    18    4.Evening  \n",
      "4147    18    18    4.Evening  \n",
      "4148    19    12  3.Afternoon  \n",
      "4149    19    12  3.Afternoon  \n",
      "\n",
      "[15127 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "! rm queries_filtered.csv\n",
    "class Filter:\n",
    "    def __init__(self, max_cell_daytime):\n",
    "        self.max_cell_daytime = max_cell_daytime\n",
    "\n",
    "    def filter_locations(self, user, daytime, cell_id):\n",
    "        max_cell_daytime = self.max_cell_daytime\n",
    "        cell = max_cell_daytime.loc[(max_cell_daytime['ip_address'] == user) & (max_cell_daytime['daytime'] == daytime)]['cell_id'].to_numpy()[0]\n",
    "        if cell_id != cell:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "custom_filter = Filter(max_cell_daytime)\n",
    "queries_df['filter'] = np.vectorize(custom_filter.filter_locations)(queries_df['ip_address'], queries_df['daytime'], queries_df['cell_id'])\n",
    "queries_df = queries_df[queries_df['filter'] == True].drop(columns=['filter'])\n",
    "queries_df = queries_df.sort_values(by=['ip_address', 'day', 'time', 'daytime'], axis=0)\n",
    "print(queries_df)\n",
    "queries_df.to_csv('queries_filtered.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "filtering queries with locations from cell_id which\n",
    "turned out to be the most interesting cells, for each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                user  day                                            pattern\n",
      "0        0.98.248.97    1  {'lat': 46.510699517190126, 'lon': 6.628843215...\n",
      "1        0.98.248.97    1  {'lat': 46.510699517190126, 'lon': 6.628843215...\n",
      "2        0.98.248.97    2  {'lat': 46.510699517190126, 'lon': 6.628843215...\n",
      "3        0.98.248.97    2  {'lat': 46.510699517190126, 'lon': 6.628843215...\n",
      "4        0.98.248.97    2  {'lat': 46.51365572536957, 'lon': 6.6291297079...\n",
      "...              ...  ...                                                ...\n",
      "15122  97.138.146.97   18  {'lat': 46.53591906517015, 'lon': 6.5754877393...\n",
      "15123  97.138.146.97   18  {'lat': 46.5205175117895, 'lon': 6.56848319255...\n",
      "15124  97.138.146.97   18  {'lat': 46.5205175117895, 'lon': 6.56848319255...\n",
      "15125  97.138.146.97   19  {'lat': 46.53591906517015, 'lon': 6.5754877393...\n",
      "15126  97.138.146.97   19  {'lat': 46.53591906517015, 'lon': 6.5754877393...\n",
      "\n",
      "[15127 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import make_dataclass\n",
    "pattern = make_dataclass(\"pattern\", [(\"lat\", np.float32), (\"lon\", np.float32), ('time', int), (\"pois\",str)])\n",
    "trace = make_dataclass(\"trace\", [(\"user\", str), (\"day\", int), (\"pattern\", pattern)])\n",
    "traces = []\n",
    "users = queries_df['ip_address'].drop_duplicates().tolist()\n",
    "days = [_ for _ in range(1,21)]\n",
    "\n",
    "for user in users:\n",
    "    for day in days:\n",
    "        serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['day'] == day)][['lat','lon','time','poi_type_query']]\n",
    "        for row in serie.itertuples():\n",
    "            pat = pattern(row[1], row[2], row[3], row[4])\n",
    "            tr = trace(user, day, pat)\n",
    "            traces.append(tr)\n",
    "\n",
    "traces_df = pd.DataFrame(traces)\n",
    "print(traces_df)\n",
    "traces_df.to_csv('traces.csv', sep=',', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "not so useful stuff..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Trajectory study\n",
    "\n",
    "Here we try to study, for each user, on a daily basis, their\n",
    "trajectories and how they differe from day to day. For\n",
    "computing the similarity, Frechet distance is used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install similaritymeasures\n",
    "!rm -r ./figures\n",
    "!mkdir ./figures\n",
    "\n",
    "from similaritymeasures import frechet_dist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "users = queries_df['ip_address'].drop_duplicates().tolist()\n",
    "days = [_ for _ in range(1,21)]\n",
    "user_trajectories_per_day = []\n",
    "user_trajectories_cluster = []\n",
    "\n",
    "def compute_distance_matrix(trajectories):\n",
    "    n = len(trajectories)\n",
    "    dist_m = np.zeros((n, n))\n",
    "    for i in range(n - 1):\n",
    "        p = trajectories[i]\n",
    "        for j in range(i, n):\n",
    "            q = trajectories[j]\n",
    "            dist_m[i, j] = frechet_dist(p, q)\n",
    "            dist_m[j, i] = dist_m[i, j]\n",
    "    return dist_m\n",
    "\n",
    "def clustering_by_dbscan(distance_matrix, eps=100):\n",
    "    \"\"\"\n",
    "    :param eps: unit m for Frechet distance, m^2 for Area\n",
    "    \"\"\"\n",
    "    db = DBSCAN(eps=eps, min_samples=1, metric='precomputed').fit(distance_matrix)\n",
    "    return db.labels_\n",
    "\n",
    "for user in users:\n",
    "    max_points = queries_df[(queries_df['ip_address'] == user)].groupby('day').size().agg(['max'])\n",
    "    max_points = max_points.to_numpy()[0]\n",
    "    trajectories_per_day = []\n",
    "    d = []\n",
    "    for day in days:\n",
    "        serie = queries_df[(queries_df['ip_address'] == user) & (queries_df['day'] == day)][['lat','lon']]\n",
    "        x = []\n",
    "        y = []\n",
    "        for row in serie.itertuples():\n",
    "            x.append(row[1])\n",
    "            y.append(row[2])\n",
    "        if len(x) != 0 and len(y) != 0:\n",
    "            d.append(str(day))\n",
    "            while len(x) < max_points:\n",
    "                #fill trajectory with last known position\n",
    "                x.append(x[-1])\n",
    "                y.append(y[-1])\n",
    "            assert len(x) == max_points\n",
    "            assert len(y) == max_points\n",
    "            trajectory = np.zeros((max_points,2))\n",
    "            trajectory[:,0] = x\n",
    "            trajectory[:,1] = y\n",
    "            trajectories_per_day.append(trajectory)\n",
    "    dist_m = compute_distance_matrix(trajectories_per_day)\n",
    "    sns.set(font_scale = 2)\n",
    "    fig = plt.figure(figsize=(40,20))\n",
    "    ax = sns.heatmap(dist_m, linewidths=1, linecolor='white')\n",
    "    plt.savefig(f'./figures/{user}-matrix.png')\n",
    "\n",
    "    user_trajectories_per_day.append(trajectories_per_day)\n",
    "\n",
    "    labels = clustering_by_dbscan(dist_m)\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    num_labels = set(labels)\n",
    "    assert len(num_labels) == 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results: the filtering was very effective. User trajectories\n",
    "are almost the same on a daily basis. In order to validate the results,\n",
    "we used dbscan clustering and checked if the number of clusters\n",
    "of trajectories per user was 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}